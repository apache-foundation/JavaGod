---
title: 多线程基础概念
date: 2019-02-11 23:53:50
categories: 并发
description: 多线程基础概念
---
# 进程和线程的关系与区别？

进程是资源分配的最小单元。线程是CPU调度的最小单元，一个Java程序对应着一个进程。

| 对比维度       | 多进程                                                       | 多线程                                                       | 总结     |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| 数据共享、同步 | 数据共享复杂，需要用IPC；数据是分开的，同步简单              | 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 | 各有优势 |
| 内存、CPU      | 占用内存多，切换复杂，CPU利用率低                            | 占用内存少，切换简单，CPU利用率高                            | 线程占优 |
| 创建销毁、切换 | 创建销毁、切换复杂，速度慢                                   | 创建销毁、切换简单，速度很快                                 | 线程占优 |
| 编程、调试     | 编程简单，调试简单                                           | 编程复杂，调试复杂                                           | 进程占优 |
| 可靠性         | 进程间不会互相影响                                           | 一个线程挂掉将导致整个进程挂掉                               | 进程占优 |
| 分布式         | 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 | 适应于多核分布式                                             | 进程占优 |



# 死锁

死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象，若无外力作用两个事务都无法推进，这样就产生了死锁。

## 四个必要条件

四个条件缩写”一球夺环“

1. 互斥条件：即任何时刻，一个资源只能被一个进程使用。其他进程必须等待。
2. 请求和保持条件：即当资源请求者在请求其他的资源的同时保持对原有资源的占有且不释放。
3. 不剥夺条件：资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占有者主动释放。
4. 环路等待条件：比如A占有B在等待的资源（B等待A释放），B占有A在等待的资源（A等待B释放）。多个进程循环等待着相邻进程占用着的资源。

避免死锁可以通过破环四个必要条件之一。

## 解决死锁的方法

1. 加锁顺序保持一致。不同的加锁顺序很可能导致死锁，比如哲学家问题：A先申请筷子1在申请筷子2，而B先申请筷子2在申请筷子1，最后谁也得不到一双筷子（同时拥有筷子1和筷子2）

2. 超时，为其中一个事务设置等待时间，若超过这个阈值事务就回滚，另一个等待的事务就能得以继续执行。比如可重入锁的超时等待

3. 数据库可以及时检测出死锁，选择一个牺牲者放弃事务，即回滚undo量最小的事务。一般是用等待图（wait-for gragh）深度优先搜索的算法实现，如果图中有环路就说明存在死锁。


## 死锁、活锁与饥饿

死锁：指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将**无法推进下去**。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。

活锁：是指线程1可以使用资源，但它很礼貌，让其他线程先使用资源，线程2也可以使用资源，但它很绅士，也让其他线程先使用资源。**这样你让我，我让你，最后两个线程都无法使用资源。**

饥饿：通常因为**线程优先级使用不当**。是指如果线程T1占用了资源R，线程T2又请求封锁R，于是T2等待。T3也请求资源R，当T1释放了R上的封锁后，系统首先批准了T3的请求，T2仍然等待。然后T4又请求封锁R，当T3释放了R上的封锁之后，系统又批准了T4的请求......，**T2可能永远等待**。

# java内存模型

*注意：没有什么jvm内存模型，要么是Jvm运行时数据区，要么是Java内存模型.*

由来

计算机采用**结构化**的存储，而存储设备与处理器的运算有几个数量级的差距，所以不得不加入一层读写速度尽可能接近处理器运算速度的**高速缓存**，来作为内存和处理器之间的缓存，将运算所需要用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回忆内存之中。这也引起了一个新的问题，**缓存一致性**。
除此之外，处理器可能会对输入代码进行乱序执行优化，因此如果一个计算任务依赖另一个计算任务的中间结果，那么其顺序并不能靠代码的先后顺序来保证。

*插一句题外话，可不可计算机全部用内存，这样就不用考虑缓存一致性了？可以，比如说谷歌公司，他的搜索引擎的数据80%存在内存里面的，才会这么快。一般的小公司如果没有钱买这么大的内存是没办法跟他做竞争的。*
那么至于Java的内存模型有什么关联呢？Java的内存模型中。主内存可以类比硬件的主内存，而每条线程的工作内存可以类比处理器高速缓存类。
这个变量是在修改后同步回主内存，在变量读取前从主内存刷新回变量值，这种以主内存作为传播媒介的方式来实现可见性的。
对一个变量执行，mx操作之前，必须把此变量同步回族内存中，一个变量在同一时刻只允许有一条进程对其进行加锁操作。
线程之间的状态转换，Java有5种线程状态，新建，运行，无期等待，限期等待，阻塞。

## 线程安全

在学synchronized和volatile之前，我们先来了解一个概念——什么是线程安全？
线程安全简单来说就在多线程的情况下也不会有问题，看似一句废话，要怎么理解呢
比如ArrayList不是线程安全的就是一个线程不安全的类，
如果两个线程对可以同一个ArrayList进行add操作会出现什么结果？请看下面代码

```
public class MyTest {
            static List<Integer> list = new ArrayList<>();

            static class BB implements Runnable {
                @Override
                public void run() {
                    for (int j = 0; j < 10000; j++) {
                        list.add(j);
                    } } }

public static void main(String[] args) throws InterruptedException{

                BB b = new BB();
                Thread t1 = new Thread(b);
                Thread t2 = new Thread(b);
                t1.start();
                t2.start();
                t1.join();
                t2.join();

                System.out.println(list.size());
            }
        }
```
问题出在add方法
```
public boolean add(E e) {   ensureCapacityInternal(size + 1);   
elementData[size++] = e;  
return true;}
```
上面的程序，可能有三种情况发生：

* 数组下标越界。首先要检查容量，必要时进行扩容。每当在数组边界处，如果A线程和B线程同时进入并检查容量，也就是它们都执行完ensureCapacityInternal方法，因为还有一个空间，所以不进行扩容，此时如果A暂停下来，B成功自增；然后接着A从 elementData[size++]=e开始执行，由于A之前已经检查过没有扩容，而B成功自增使得现在没有空余空间了，此时A就会发生数组下标越界。

* 小于20000。size++可以看成是 size=size+1，这一行代码包括三个步骤，先读取size，然后将size加1，最后将这个新值写回到size。此时若A和B线程同时读取到size假设为10，B先自增成功size变11，然后回来A因为它读到的size也是10，所以自增后写入size被更新成11，也就是说两次自增，实际上size只增大了1。因此最后的size会小于200。
* 等于20000 很幸运，没有发生上面情况
顺便说一句，线程越多，或者加的数越大越可能出现不安全的问题

# synchronized：“这条桥上一次只能过一个人”



## 关键词

互斥、JVM内置锁、对象锁、可重入(避免死锁)**

## 有什么用

- **原子性**：确保线程互斥的访问同步代码；
- **可见性**：保证共享变量的修改能够及时可见，其实是通过Java内存模型中的 **“对一个变量unlock操作之前，必须要同步到主内存中；如果对一个变量进行lock操作，则将会清空工作内存中此变量的值，在执行引擎使用此变量前，需要重新从主内存中load操作或assign操作初始化变量值”** 来保证的；
- **有序性**：有效解决重排序问题，即 **“一个unlock操作先行发生(happen-before)于后面对同一个锁的lock操作”**；



## 怎么用

当synchronized作用在实例方法时，监视器锁（monitor）便是**对象实例（this）**；

当synchronized作用在静态方法时，监视器锁（monitor）便是对象的**Class实例**，因为Class数据存在于永久代，因此静态方法锁相当于该类的一个**全局锁**；

当synchronized作用在某一个对象实例时，监视器锁（monitor）便是**括号括起来的对象实例**；




## 为什么

想了解synchronized的原理，首先要了解两个东西：对象头中的Mark Word和Monitor，说白了，前者是资源的锁，后者是拥有者线程的锁记录。加锁要修改拥有者和资源的锁记录才行。

加锁的时候**首先要添加拥有者线程的锁记录**，虚拟机会在当前线程的栈帧中建立一个名为锁记录( Lock Record)的空间,用于存储锁对象目前的Mark Word的拷贝

**然后要修改资源的锁记录**,虚拟机将使用**CAS**操作尝试将对象的 Mark Word更新为指向 Lock record的指针。如果这个更新动作成功了,那么这个线程就拥有了该对象的锁,并且对象 Mark Word的锁标志位将转变为“00”,即表示此对象处于轻量级锁定状态。

### Monitor

Monitor是**线程私有**的数据结构，每一个线程都有一个可用monitor record列表，它依赖于底层的操作系统的**Mutex Lock（互斥锁）**来实现的线程同步。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。





### 对象头中的Mark Word![多线程概念](C:\Users\home.11\Desktop\小a笔记\images\多线程概念.png)



**对象头**：Mark Word（标记字段）、Klass Pointer（类型指针）、数组长度数据（可选）

**实例数据**：存放**类的属性**数据信息，包括父类的属性信息；

**对齐填充**：由于虚拟机要求 对象起始地址必须是8字节的整数倍。填充数据**不是必须的**，仅仅是为了字节对齐；



**Mark Word中四种锁状态标识**

| 锁状态   | 存储内容                                                | 存储内容 |
| :------- | :------------------------------------------------------ | :------- |
| 无锁     | 对象的hashCode、对象分代年龄、是否是偏向锁（0）         | 01       |
| 偏向锁   | 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） | 01       |
| 轻量级锁 | 指向栈中锁记录的指针                                    | 00       |
| 重量级锁 | 指向互斥量（重量级锁）的指针                            | 10       |

*注意：无锁和偏向锁使用的是一个标志位，但偏向锁还有是否是偏向锁标志位、线程ID、Epoch等*

接下来我将顺着标识位来讲synchronized的四种锁状态。

### 四种锁状态

JDK 6之前synchronized效率低，是因为依赖于操作系统Mutex Lock，即“重量级锁”，阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。

JDK 6之后的synchronized锁级别从低到高依次是：**无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。**

| **锁**   | 消耗                                                         | **缺点**                                       | **适用场景**                       |
| -------- | ------------------------------------------------------------ | ---------------------------------------------- | ---------------------------------- |
| 偏向锁   | 加锁和解锁时对比Mark Word，只需一次CAS原子指令               | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 | 适用于只有一个线程访问同步块场景   |
| 轻量级锁 | 将Mark word拷贝到栈帧的锁记录中，再将Mark Word替换为锁记录的指针。多个CAS操作和自旋。 | 自旋会消耗**CPU**，但相应时间快                | 追求响应速度，同步块执行速度非常快 |
| 重量级锁 | 依赖于操作系统Mutex Lock，等待线程被阻塞挂起                 | 线程阻塞**响应时间缓慢**，但不会消耗CPU        | 追求吞吐量，同步块执行速度较长     |

#### **偏向锁**

HotSpot发现：在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。

当一个线程访问同步代码块并获取锁时，会在Mark Word里存储**锁偏向的线程ID**。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在**无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径**，因为轻量级锁的获取及释放依赖**多次**CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖**一次**CAS原子指令即可。

偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待**全局安全点**（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。

偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。

#### **轻量级锁**

是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，**其他线程会通过自旋**的形式尝试获取锁，不会阻塞，从而提高性能。

虚拟机会在当前线程的栈帧中建立一个名为锁记录( Lock Record)的空间,用于存储锁对象目前的Mark Word的拷贝。
然后虚拟机将使用**CAS**操作尝试将对象的 Mark Word更新为指向 Lock record的指针。如果这个更新动作成功了,那么这个线程就拥有了该对象的锁,并且对象 Mark Word的锁标志位将转变为“00”,即表示此对象处于轻量级锁定状态。即上面说的加锁要修改拥有者和资源的锁记录才行。

如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。

若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有**第三个**来访时，轻量级锁升级为重量级锁。

#### **重量级锁**

升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时**等待锁的线程都会进入阻塞状态。**



## volatile
### 有什么用

volatile是一个关键字，用于修饰变量。被其修饰的变量具有可见性和有序性。

- **可见性**，当一条线程修改了这个变量的值，新值能被其他线程立刻观察到。其实这里要结合Java内存结构来说：在缓存在本CPU对变量的修改直接写入主内存中，同时这个写操作使得其他CPU中对应变量的缓存行无效，这样其他线程在读取这个变量时候必须从主内存中读取，所以读取到的是最新的，这就是上面说得能被立即“看到”。
- **有序性**，即volatile可以**禁止指令重排**。volatile在其汇编代码中有一个lock操作，这个操作相当于一个**内存屏障**，指令重排不能越过内存屏障。具体来说在执行到volatile变量时，内存屏障之前的语句一定被执行过了且结果对后面是已知的，而内存屏障后面的语句一定还没执行到；在volatile变量之前的语句不能被重排后其之后，相反其后的语句也不能被重排到之前。

### 经典场景

chm的get方法是**不加锁的**，因为get方法里的共享变量都定义成volatile类型，保证能被多线程的读，但只能被单线程的写。即使一个线程在读一个线程同时在写，根据happen before原则，对volatile字段的写入先于读操作，所以get总能拿到最新的值。这是用volatile替换锁的经典场景。

## 生产者消费者
一个非常典型性的线程交互的问题。

1. 使用栈来存放数据
1.1 把栈改造为支持线程安全
1.2 把栈的边界操作进行处理，当栈里的数据是0的时候，访问pull的线程就会等待。 当栈里的数据是200的时候，访问push的线程就会等待
2. 提供一个生产者（Producer）线程类，生产随机大写字符压入到堆栈3. 提供一个消费者（Consumer）线程类，从堆栈中弹出字符并打印到控制台




